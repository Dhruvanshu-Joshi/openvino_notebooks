{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9sAAABnCAIAAACfC8YYAAAAAXNSR0IArs4c6QAAIABJREFUeAHtnYlfUtn7x3//EyoguGuamZWpaTVm0zYtVmab2jJZZtM2ld/KbNq0fTcV0tEWdXJJ0SyEC7imgpWiloGg8HvRqfvlS+Dcy3ouPr14zRwO557z3A9nefP4nHP/zwj/QAFQABQABUABUAAUAAVAAVDAcwr8n+eahpZBAVAAFAAFQAFQABQABUABUMAIRA6dABQABUABUAAUAAVAAVAAFPCkAkDknlQf2gYFQAFQABQABUABUAAUAAWAyKEPgAKgACgACoACoAAoAAqAAp5UAIjck+pD26AAKAAKgAKgACgACoACoAAQOfQBUAAUAAVAAVAAFAAFQAFQwJMKAJF7Un1oGxQABUABUAAUAAVAAVAAFAAihz4ACoACoAAoAAqAAqAAKAAKeFIBIHJPqg9tgwKgACgACoACoAAoAAqAAkDk0AdAAVAAFAAFQAFQABQABUABTyoARO5J9aFtUAAUAAVAAVAAFAAFQAFQwPNE/mlC/2lCT3zUSD58re8bf9k1ViFTl0pGZs9LQKhfdI3Vdo9JPnwlPmqUn3WfJvS6KQP0TlAAFAAFQAFQABQABUCB2aCAB4hcN2V4PzrZ0v8ZkXeFTC0k1ALpLELwGX5slEtHBIS6QqYu+5ao7xt/Pzo5oZueDX2x//MXeHmHAlMGHH9PTquq4MV0BQz6z7hNht4xZuEu+j9/wa1ruc+eKY1hotcw0Tv9oUY/9HI2vKY/1KBbdp/IFFpyK5ErP+vq+8bLpSNPidnlBZ8Bwf/1IwFhovPqztH3o5Pe7Tjv+DgsGlTBi+kKtCmH8CRyveSoXpwLL+YqMNVxFEMibx/6yPQxC/aLBlVtyiEKyOQNRQy60enhJt37J5quIo28EE0Io8SVEekVhfwpQQhnw6tHVjIivTxKXEG3r5EXaruKde+fTA83GXSjnvqa3UHkuikD8VEjIEy+8H8FUChgSwHTXxKIEdHAF291mX8j8iGREl7MVgCInLnIi7nl+BI5zFrMV8DridygUekHK7XS/K+SM/2ye22y2gZ5a51cLOxUwatOLm6Qt7bJagdk975Kzmil+VPKvw0alZvR3LVETrK4gICgFOcoUCYdKZOOtPR7IZcDkXvHrxEgcsy5lrnmAZF7xxSB5114MZEb1O1a+cUJyRmCEAKCU/n5UScXdxGPJyRntPKLBnW727jchUT+fnRS8M2ta8vpC/l2K1AmHRHK1MRHjds6ihsaAiLHc6GiaxUQOXORF3PLgcjpDkYoT10BLyTyKc30h5pJyfEPxI0GeSsVEoUyFgq0yBtHpJc10vzp4SY3UJBLiHxCN13TPSaQQoyKc/zitsBdKFVXytSfJvRu6ChuaAKInPrigXNJIHLMuZa55gGR4zzwmW6blxG5Qd0+KTk+ILv3XKGwoEx4S1eB5wrFsPSyVppvGCdcykLOJ3LluA5iVGwxtCvyy6Qj3uEsByJn+pKG7AciZy7yYm45ELl3TBF43oXXELlBN6rtKlITVyBAhS55z1y+Qd46ThRou4pdt/XTyUTerpqA7ZuuwO6Z6xQS6pruMaafxAJEjudCRdcqIHLMuZa55gGR0x2MUJ66At5B5NPDTRppvlhWNTNcwqd2KyCWVZmCWNRvXOEsdxqR66YMNd1jQohU8dCzjcokI1Wdo2OaKVf0EvfUCUROffHAuSQQOXORF3PLgchxHvhMt43xRD6lmey9Oy4tgDAVu2mb4oV1cvFnokDX/8Q45eS9fM4hct2UobpztBye8uMhHCc96AJCzVwoByJn+pKG7Acix5xrmWseELl3TBF43gWjidwUqSK/+J64S5EpoZiDClQpevtldyflF50L5U4gcoTjJBRCwrMKCIgRhkI5EDmeCxVdq4DImYu8mFsORE53MEJ56gowl8gNGtWk5HibrNZByoTL6SpAEEKNvNCJx5Y7SuSA457lb6utM9RTDkROffHAuSQQOeZcy1zzgMhxHvhMt42hRA44ThejnVu+TVY7KTnuLCh3lMhrusfKIFjF08EqP3N5pUzNuI2eQORMX9KQ/UDkzEVezC0HIveOKQLPu2AikQOOOxev7asNQblTwlccInLRwBc4WeVnGsYk51nnqHt2ZDqrFSByPBcqulYBkWPOtcw1D4ic7mCE8tQVYB6RT2m0RD4Eq9iH0c69qk1Wq3VGTLn9RN43OvmUgGcAufYZQI7AvVCqfquccBYuu6EeIHLqiwfOJYHImYu8mFsORI7zwGe6bYwj8knFRYIQOpcsoTa7Fegj7mp77jpISnYS+YRuWgA4jl+wigXBCwgmPdETiJzpSxqyH4gcc65lrnlA5N4xReB5F8wi8ill5RBxw258hAtdocCI9PL0hxpHoNxOIq/pHrOAP3iLpwIVzAkoByLHc6GiaxUQOXORF3PLgcjpDkYoT10BBhG54UvPV8mZKkWvK7AS6rRbgSpF72THMcOXHruh3B4i7xudhCcB4cnfP1tVLh15w5DYFSBy6osHziWByDHnWuaaB0SO88Bnum2MIfIpjVaa3yBvtRsc4ULXKdAib9QS+Xbv8qRN5LopA8Sr/Ay+OOeUSZlxQjkQOdOXNGQ/EDlzkRdzy4HIvWOKwPMumELk+sGKHlmJ65gSanZQARVxY8re2BXaRE58/Cog8N3OiDMZe9C2mu4xu/+M4rYLgcjxXKjoWgVEjjnXMtc8IHK6gxHKU1eAEURuOu6w4xjEqzgIzS69/Hvsis6ew+7oETk4yD1I1Y40zYgtnkDk1BcPnEsCkTMXeTG3HIgc54HPdNsYQeTarmI47tClPO2UyglCqH1fYoc3kx6Rg4PcESz27LX4u8mByJm+pCH7gcgx51rmmgdE7h1TBJ53gT+RG770TEjOOAUZoRKXKlCl6NV2HDPQd5PTI3KIIPcsVTvSepl0ZEI3bcePNrddAkSO50JF1yogcuYiL+aWA5HTHYxQnroC+BO5tucuOMhdStJOrNzkJu+n7SanQeSmI1bgDHLszyC3Re1l0pF2vA9dASKnvnjgXBKIHHOuZa55QOQ4D3ym24Y5kRt0o5Mdx5yIjFCVSxWwL5qcBpG/6h23RXuQzwgFBITabQ5vOxoCImf6kobsByJnLvJibjkQuXdMEXjeBeZEPqWs7CYeuxQioXLnKvCeuDs93EiLhagSuW7KUC6FI1aYrYCQUCvHdbT6hzsLA5HjuVDRtQqIHHOuZa55QOR0ByOUp64A5kSuleY/Vyici4xQm0sVqJOLtdJ8WhBFlcjhqUCM8IL/q5HNA59p9Q93FgYip7544FwSiJy5yIu55UDkOA98ptuGM5EbNKrPRIFL8REqd4UCE5IzBo2KOkdRJfJ6CFlhbAS5OaZXyPANXAEiZ/qShuwHIseca5lrHhC5d0wReN4FzkSuH6wgCKErkBHqdKkC3cTjaTpPC6JK5HDKijnXMjctINTYnrgCRI7nQkXXKiBy5iIv5pYDkdMdjFCeugI4E7lWfrFOLnYpO0LlrlCgQd6q6Sxyso98QjcNRM5cCje3XEio+0YnqfcPd5YEIqe+eOBcEogcc65lrnlA5DgPfKbbhi+RT2nglBVX4LJ76tSLc6lzFCUfuXJcJ4RtnV4RtVIqwfcMRCBypi9pyH4gcuYiL+aWA5F7xxSB511gS+SGLz0jxBX34CO04nQF1MQVw5ceilBOiciJj1/N/ayQZrQC2D68E4gcz4WKrlVA5JhzLXPNAyKnOxihPHUFsCXy6Q81MhkEkauczsruqbBHVkL9DERKRA7bOhmN4BbGY7u5E4ic+uLxc8nt+3/fmLH953z35wCR68W5VUUbI0L8mcu+tCzP25WYnbaQ1iX2FQYid/9wdnWLWE1cFB2Zbi6mfV8Cj+pE9ByzOOFAwWX3kLSzWhHLqnSDFRT7DCUif9k1ZkF1mL/ddfRcVGwc5kZ60DyKncPpxVpbW/v7+21V6zoi35KZyfrxj81mxyxceOKvS3avNOdu3vpRGcvX1zciKmpXTs6rrh67K3TKhcJmUXlTs1OqcrASDxJ5WVnZ2NiYrQ6mlxy1DwT14lxZ5e4dv8WGBXO5HL/YuYGn9iWPiw7MUJuLiPzZ9U2rl0UG8Nh8f3ZyXNi9/6yewQa3fdRVnSn/e7cbmvMUkVdVVQ0PD9vqV+1DHx0cMrYuj4qJIacaHp+fuHz5zaeVtgr/a75zp8F/bY5iAawmLltfsavzHzx4MDlpc3+XprOoQd7qLEB0XT13XovJ7spisdgcztwFi3IuODPehiTyay+b/vP4qevuxYk1N8hbtZQ3d1Ii8gqZ2oP4aEfTQOQzi+bq+cVW/a2trfHx8QUFBVa53KVEnrJmbfU7cfU7sbBZdPpqEZvNPnfrtvma8fr9gPnbGdLnbt7iBQSg2irb2q+VlkVGR2/NyjK/pHlA2TygNM+ZPWnPEnlSUtKNGzescrndRP6mdDvfn719XWzD/a2yyt2CS+sXzgv6JSFc+/aQLQx1nMg17QctKr91epWfr8/p/Uvby7Z3CHdeP7kygMc+lrXEopjr3s5wv65r1LxmDxJ5fHz8tWvXrHK5S4n89xMn0VRT2tC0K+cgh8t92tJqPplQn7i2ZGY6cRo0t8E70h6MWikqKkpNTbXF5Ux5NhAi8vyHgjuvxXdei4vrWg4UXPb19TtafNdZgEsSeUbu0a05ec6q1qX1NMhbvyqu2YIii3xKRD4z3mH4qTmRxyxOyvrzYkLK6uCwiHlxS64+a1+5eWdY1LyI6NhzT+qQ8Qcv3JoTs4DN4YRFzcspuIUyH7Wr1mTs4QcGh0VGHy16EhIRdfxGealk5NEb1dod+/iBwQHBocmrNxbXSjBUYAaTKmXqTxN6i37gnreIyOO//fuZy11K5Ks2bjRfNjbt2LkmbbNIObTzQE56VvbK9esjoqJEyqHKtvYVa9fx+PzwOZHb9//e0NNnfhVKn7t5ix8YaJ6fX1QcGBwsUg5devho3oKFh06f4XA4T1ta67t7M/buC58TGRgcvGLtugpRG7pK0NySvCKVw+FERkfnFxWjTKtNN70fSM/eExwayvX3j09OvvfshUg5ZDWT/OPvlcdP5i1YmF9UHLt4cWhExJq0zU19/SLlUGNf/9asrMCgoDlz5/714GF4ZOSVx0/M78JZac8SOepdVrncbiJPWhS6aeU8czRUvdq7MTW6qzpTL87te5Gd9uu80CDu3Aj+we3xYy0m37k5kVstILi0PiYygKxzY2r0+UPL9eLcJQtDrx1PXRQTtGfzIvJTvTh3qH4fl+N36Y8U88yaW2m7Niz4+sbE7lZbOZ695OD2+KNZSxbFBEWF8y8c/kUvzv1zX/KaZZFkPZXXNgQFcCbacr605hzcHh8SyAkL5m5ZFdP3Mlsvzh1u2s9isUourAsJ5Dw4u6bvRdbG1OhAPjsogLN1dYzq1V69ONc8aqX+3tbl8eGBfPbCeUHFJ1fq3pl+tCxdHHbr9Kotq2IWRAfFRAW8uJFGtk4r4VkiR13r6tWrFlzuUiI/WnDBfGBGREWduPiXSDm0ID7+yLnz82IXbNy+g+LEtSUzk+I0SGviuiGsWJiQ4M/jRc+PRbYhe1LWrOUFBPADA3/dsOFFh9RWJjlx7T54KD17z66cnHmxC8LmzMn58xS68eq34uWrVvH4/LglSVdLSlkslov+IOlZIke9KzU19f79+xb+cr0416XI6KzKEZFfqX5lXuGvWzJS07ainP88fhqzOIHL482Jid1/9i+UebP+TdKqtf78AF5A4LJ1G+61SISdqt927Vm9bSdZD5vDOVf6t7BThYg8I/eoj6+vnx977oJFZBlsE1WKXurHrXg/kS9IXBYVG3e7ofPxuw/z45MDQ8IKyutLJSO/7TqQmLq2VDJy9Vm7j4/PydsVJeKPp+9X+fmxrz5rL5WMZOSeComIuvq8/W5z79K1aWwO5+TtilLJyKY9hxNS1txp6n7UrtqYnRuzOGkG/MXwowo8iBxNQOZc7k4iT8/KXr0pTaQcyj6cFxIenl9UXCtTiJRDcUuSsg7nNfb1v5TKklek7so5aL4covTPRH7+1p3AIBORXystCwwK3vH7gRcd0ub+wfTsPQnLlj0XSxp6+rbv2x8ZHd3cP9gyqFoQH78r52CtTHGrsorD5SLOttr0sQuFC+MTXkiI1+8Hjl0ojIyObhlUWc0kF7aisnIOl5t9OE+kHKrv7g2PjMwvvi5SDv1+4mR4ZKSwWVQrV6zauJHN4RSVlf98d47n4EDkJJdfv36d9JfbR+S9L7JYLFbTg3Sr7Dj59tDi+cGHdyWMiw4M1e9LSYxAJE0Sua0Ctoh8eXz44vnBrSUZo83/ExXz6Pxaf67fRJul4xxZZauVU/uSA3jsZ9c36cW50qe7fHx8+l5kt5dt9/X1GW76HV2bnbZw35Y4vTj3ePaS31LmfmzYP9GWcyxrydLFYXpx7ufWHBaLtXV1TN+LrM+tORnr5v++bfHn1hz169/JC0kif1+TzWH7Pilcp3176F35jtAg7sNza/Ti3JTEiPlRgT3Ps/Ti3JunfjX/KWJVVVuZOBD5z1zuTiKPjo09dqFQpBxanJQUs3Dh/ecvX3V2U5y4fiZyW9Mg9YnrhYTg8fmXHj5qHlCW1jeGhIWh3/mrN6Vtycxs6On7R9G1MWN72s5dIuWQ1Uxy4srOO8Lj89HlpfWNPj4+lW3tIuXQ0tTUlDVr6xSdgtfNC+LjTYPxm4vB8ZnKogYciNwqlzOayFel70zZsFnYqbonknJ5/BO3Hgrkg1efNwSFhv15p0TYqfplfdraHZlPOnofve38det2BOIzE7mwU7V83Uam+MiFnSog8v/GkS9IXLb1wHFExut358QtTUXpvCsPI6Lnl0pGnog/3W7sItE5LGpe3pWHpZKR+QnJ2w7+ifILhY0sFuvk7YonHcNcf97ZxzUo/9EblZ8f+9LfIvJy/BNYETmagC5cuDAwMOAeIm8ZVN199pwfGHjmmsk5nZ13ZF7sAjQ1P3hZy+ZwmvsH0dsbwgrk+baYuC2IvLKtPW5JEvJUFZWVs1gs5BBqGVCy2eyrJaXo8lqZgsVi3a1+9uBlrR+bTbp5rpaUljc122r64KnT8cnJ5AqEImGsZpILG7LhH0UXanf1prQ9R/5AS/j+Y8dR5uO6f1gsltcTuQWX20fkr+5uZbFYnxr3W8XE5kfbfH19Rl5/p9vKaxu4HF/t20MkkdsqYIvIUxIjDm6P/7mt/ANLExaE/JyPcmy1cmpfcnKcCazRKySQW3t7s16cGxMV+KRwnV6cq2k/GBzAqbmVpnt3iO/Pbn60DZX80prD9vMlKnZNtB1ksViCS+tR/m8pc//ITETpyR9BOySRFx7+ZVl8OPpUL849sjvxt5S5iMjJ6BrJ050sFsvWTwvyWqsJfIjcnMvdQ+RN7wf+vHzFj81G20Xily5Nz96DhrOt2QN9Sv7XnMhnmAZpTVx5/zm7fNUqsom9fxxFf3tcvmrVzgM5KL/lR/ye1Uxy4srOO7IoIZGsKjAouLhc8Kqrx8fHh4ye/+N8wWwgcgsuZyiRC+SD+Y+EbC4399J1Yacq68+ziamrSE/2ttyjiNQTU1dt2nMA5QvkgygBRD5T2AL+lGlhoXnUyoLEZXtOX0YF0vbmpWzchtLHrpeGRESaiLxjeEdeflRsXGBoeGBImI+v78ELpsCV4LCInIKbqPCjdpWPr+/J2xU3601cZfHvxE2BhQE4v62QqZvFcjTm3fzfjIyMGVr8R64QDQ6RM7ITE1syM318ff15PH8ez4/NZnM4+44ebRlUISJfsXYdaqvg9l2Lbxb9hXTTjp0+vr4+vr7Lfv1VpBxCOztRbWwOx9fXd03a5lp5p0g5VFRWzuZwUG3Vb03bXATNLeSNBAQGnbt5q+D23bA5c8jMmZt+0SFdEB8fGBS0ftu2C3fuobXNaia5sBWVlfMCAsj6f0tP35VjWhpDIyLICJnGvn5fX1/XEfnd+/dn+KJd99GhQ4dsVZ6UlKR9d9gq582c2fQgncViDdXvs1rsSeG6OaE88qMO4Q4Wi9Vfu4ckclsFZiDyy0dXkBWSifOHlsfFBJNvLRK2Wjm1L3nr6hiycESIf1XRRr049+Te5O3r5uvFuTW30kKDuNq3h5T/7P258z+/sQkReduTDFRJ86NtIYGc+VGBebsSXz/8/ncDksj3p8ft3riAbO76yZXzowIRkRefXInyFVW7WSwW+RuGLEwlcfvsFlvfr0vz8/LyZqj/tWtctiLlUFRMDJvNRlONr69vSHh44b37aGjHL116OP8/M88eFhMXxWmQ1sSVnr3HotvELUkSKYfuVj8LDAqKnDdv+/7f71RVIzutZpITV3bekV83bCAnrpCwsEuPHgtbRCwWCznLRcqh64KnLiXyO3fuzPBFu+6j7OxsW5WnpqYyi8jZXC6Xx+PyeH5+bH5Q0I4jJwQKJQpEsegqsQlLhJ2qgvJqflBQ+Nx5G7P3ny+rBiKficXRZzjzpVXbLIh875krqFja3rwVGzNQmiTyA+dv8INCCspMoSylkpE58xYgIg8KDUcJlM/mcE/errjd2MVisZjlFEf2k/+dnT7y5atWPW1pfdrSWtX+jvTZICInYysv3Lln1Sle/U5c2tBU2tCEFgbTzk4+H9VW2fqGdGAjIidDzNHCJmwRkWsMPzDw3M1b52/dCQkPJzNRwlbTIuVQ84Dy9t9VWYfzQiMiflm9Gv2Q+DmTXNiKyspJG0TKIZLITcE538JXUIucWRC1gha5pKQkFLtin498oM7EHMi1bE6NaOflk8J1kWHmRG5yAA/U/Q+RWy1gQeTrV8xFceQpiRHFJ77Dq3lzTwrXcdi+FqEsyMmtF+faMuPUvuT0NVaI/E3p9gAee6ItJycjHrnkh+r3sVgsomKXeaN6cS4i8g7hTjL/c2tO5bUN+9Pj/Ll+F/NMce3mRJ5pRuTFJ1bGzv1B5D9uyhEin4U+8r1/HEVTDfrLGzlvxC9dSoaY25o9LCauLZmZVKZBWhPXtj17kVOcNIxMNPT0/fXg4ebdmRwu99DpMyj/50xy4srOO0JOxSLlECJyQXOLOZHfe/bCpUT+7zDkmhJFRUU/EzkZU84sIv/zTsn1f0TX/xGtSt+5eHkK6fZev3svcoqTbnIy8aSj9/jNB2u272ZzubuPnf45jtyPzTaPI4eoFROqMuhFi8hXb8siMf1OU7cfm4NAfN6ixO15Z9BdX/rb9Ev9e9QKj593+QGpBuN2dmJF5AUFBQMDA2iWc0/UCrlgoIT5MvCwppbFYj1714E+etXZXSs3BZdbvCyiVsw/Nadh0x9/ORxy9+QLCcFise4/f3n/+UsfX1/kU0ce91uVVbaaftXVU9/di5qofmdyule2tVvNJBc2cxvMiXxhfAK5Waq0oWk2RK2QLI46mH1Ejly8qUsiyCANvTj3Q/2+mMiA5kfbRCUZ32Kyv8e0CC+v53H9Js2iVmwVqC7eZE7qcTHBMxP5cNPvPK7fqX3JJBnrxblND9LnRvBHmw/YasUWkZsCVyIDXt5MmxPKq7+3VS/O1b07FMBjl/+ITjFtFf22s9OCyM3/VlB68bd5c0ybU0kiv5j3i3mQTO7OhI2p0d995N5F5Ob7O90TtWI+z4iUQ+ZEbmv2sLjEPGrF4iPzaZDWxJV39lz0/FiytudiSdO3Q6teSAgy89yt22jfvNVMcuIyt4Ek8n8UJhcY6WU/cfGv2UDkJIt/n7iYubPzUbsiKCx875kCRN7Zf56dExNLUvjd5o4yoh/Fl5OZR67eCouMEnaq0vYdXLl5G8q/J5KyWCwg8v/+GCTpkykJWkS+7dCp6EUJD1oHbjd0Ll2zKXxuzM4/zpZKRtL2HYmIji2uldxr6UvZkI585GhnZ1Tsomsv3j5+O7Tr6LngsIhH7SqmKFMqGXmKx85O8z2dmBC5SDm0KHHJui1ba+WKWrliTdpmq+4fikQuUg5l7N23OCmp+p34VWd32s5dMQsXNg8oWwZV8xct2pKZ+aJDevNpJY/Pv/vsua2m123ZuiEjo1amaO4fvHDnHtffv76712omubDZIvKs3MNz58//+83bOkXnui1bvdtH7tyzVsSCHQE89oYV0f/c2UKefrh+xdzJt4d07w7FxwajI1b6XmYnLQpFLmcyasVWAfnfu318fDqEO0wOsMvrA3jsmYlcL859cHaNr6/Pkd2JrSUZHcIdxd9OP0THp9hqZQYiP7Enac2yyIgQf/KXxvHsJYvnB3c/y/z65uClP1Iiw3gTbTnmRK59eygyjFd8YuVE28Fx0YE/MhNXfzuzhSTygbo9HLbv44K1X98cbH60LSiAgwLQzR3/TPeRm7M4mrg8TuS2Zg+SiVGCIpHTmrheSAgOl3vk3PnGvn5hs2he7ILjhReb+wdDIyKOFlxo6uuv7+7deSAneUWq1UyRcoicuKwS+bcNMMlr0ja/6uoRtojiliR5N5FbsDijiVzYqTp+8wGby71e14LIm83lZp86Vyp9X1zXEjk/dv/Zi+XygeDwiL1nCkql70vEPZv2HFj8ywphp+rA+UthUXNLxN0ChTJt30GLs1aEnarUtPSUDZvvtxIkzeOccPLOTkafR74gcdnMUSt3mroTUtZwefyo2Lgz96uzTl7k+vMOnL/xoHUgZUO6Pz9gzrzYP+9U+vMDTt39u1Qy8vCNct230w+5/ry4pakXK14zCMeRqf/9seXelAfPIzf/e6j5QmWxDFSI2lLWrOX6+wcEBv2Wnu6Ij1ykHHrV1bNpx05eQEBgcPDqjZuq34lR02WNr5NSVlicfmi16RcSYk3a5sCgYK6/f9ySpOuCpyLlkNVMcmGzReSvunrWbdnKCwiInh9bXC7gBQQUC4TmUjgr7dmzVqyy+PeFzYEnBHVWZWZtWjgnlMfl+MbFBF/M+4U8L1xRtXvt8ijudThJAAAN7UlEQVR/rl90BP9Y1hK0Z5Ekcr0412oBvTj39P6lc0J5cTHBJ/cm79m8KP/AUgt3srk7HKVrb2/+LWVuSCA3gMdesSSC3HBpq5UZiLztSQaLxcrblUC28vnH6Yd8f/aqpZEoUsWcyPXi3LYnGalLIgJ4ptMPN62MRsenkESuF+c+u74pPjYEqXT/7PcHGHkHkXvkPHIyNMVieJr7yEXKIauzh8Ul1Imc1sRVLBAuTEjgcDhhc+bsP3Yc7T5/8KImcflyHp/PDwwkD361mklOXBZTMYpaESmHBK+b45cu9efxlvyS8teDhyYip/zsCAsFZn7r2bNWvOY8covTD39Zn7YoeTmKXcl/KIhZnMDmcEIi5mw/fBxlXnz6clHycn8enxcQmLRq7Y1XpmchPRZ3L1u3ISgsPHrR4iPXbofOiUTPAyLPIz91r5QXEBgcHoEziCPbnH8eOeOe2eksRH74RomqetA2yGKxLle1Oqtmz9bjXg7/b2ueembnzBPx7PmUPF69vruXxWKVNb52xb17lsjJsw7/2+1+pOyOWiGZFRKeVcCDceQWZ5D/6FOm/7vOR+6K4cm4OpsHlI0/9s5eKy0LCglx0S14kMhtPRsIdTOmPLMTfzj2iIXOf2Znfe+4ZwnSI63vy78aOmfu1WftD1oHNu05HBE9//G7Dx6xxLmNPpWpzZcTfNKuiyN30QzOrGpP/HUpIipK0Nzyqqtn98FDUTEx1J/2R+tOPUjkM3dmIHLP8rTjrXuKyGfuV0DktOYHuoXXbdmauu63GkL+XCxJXpG6acdOujVQLO9BIp+5g2nfl7TJaj1Ck9Co4wqIZVW6wYqZv2LyU0pPCCI+fnUuFDKithLxx43ZuYEhYVwef/GylX9VNDPC7H81sqZ7jPz6sUoAkVNcOewr1tw/uCsnJzg0lMfnJ69IffKqwb56/vUqIHLH0RNqsKoAEPm/jj7vK/BcLFm5fj2Pzw8KCUGbalx0j9gS+fSHGplM6DgaQg0eUaBHVjI93EiRtSgRuXJcJ5Qy6ayVf6XS2VxA8uErxc7h5mJA5C5aadxcLRC5VZqETMcVACJ381ieVc1hS+SGLz0jxBWP0CQ06rgCauKK4UsPRZqiROQTumkhoZ7NFOs19y4k1H2jkxQ7h5uLAZF7x/oHRO44ekINVhUAIveOKQLPu8CWyI1TGq3kuONoCDV4RAHqB60YjUZKRG40GsulQOTe8FcCIaGe0E27GbUpNgdEjudCRdcqIHKrNAmZjisARE53MEJ56grgS+RGo1ZeWCcXewQooVFHFGiQt2o6iygiEA0in52bO73GNU7eSAWu2zqNRiMQOfXFA+eSQOSOoyfUYFUBIHKcBz7TbcOZyPWDFQQBoeQqR+DYI9d2E4+nP9Q4n8j7RieF4CZn1INLSQo3TzQPfKbeOdxcEoic6Usash+I3CpNQqbjCgCRe8cUgedd4EzkBo3qs/SCR5gSGnVEgQnJGYNGRR2lqEat6KYM5YQ3hG2Y4+lsSwtkauW4jnrncHNJIHI8Fyq6VgGRO46eUINVBYDI6Q5GKE9dAZyJ3Gg0aqX5zxUKR+gQrnWzAnVysZbIp8VRVIncaDS+mpWnknsTtZdLMT2JHHVZIHLqiwfOJYHIrdIkZDquABA5zgOf6bZhTuRTyspu4rGbmRKac0SB98Rd6uceIgqiQeSmwBU4cYWxgStl0pF25QStn2tuLgxEzvQlDdkPRO44ekINVhUAIveOKQLPu8CcyA26UThxxRE+dvO1VYreSclxg26UFkfRIHI4cYXR/vJy6Qi2p6ygLgtEjudCRdcqIHKrNAmZjisARE53MEJ56gpgTuSmwJWeu/DwTjeDtd3NEYRQ+76EFo7TOGsF1Ut8/CqAaHJmusmxfVQn2WWByKkvHjiXBCJ3HD2hBqsKAJHjPPCZbhv+RG740jMhOWM3I8KFblOgStGrpe8gp03kpv2dcOIKA4lcSKg/TehJ9sUzAUTO9CUN2Q9EbpUmIdNxBYDIvWOKwPMu8Cdyo9E42VkEbnK3gbXdDdnnIKdN5EajEdzkTIxdwd9BDueR47lK2WEVELnj6Ak1WFUAiNyO8QiXUFSAEURu0Ki0kuNVil67YREudLUC9kWQIz8pvThyo9EIbnLGEXm5dGRMM4WnX9zcKvCRU1w5MC8GRG6VJiHTcQWAyDEf+4w2jxFEbjQa9YMVPbISV2Ml1G+3AirixhSdpwKZUxBtIjcajX2jkwI4dIUhsSsC6cgb5RfzrxzbNBA5o9cz0nggcsfRE2qwqgAQOTnKIOF0BZhC5MYpjVaa3yBvtRsZ4ULXKdAibzSdQT6lsQ+07CFyo9FY0z3GOFfx7DT4qUytmzLY1zncfBUQudPXGI9UCERulSYh03EFgMg9MqJnSaOMIXKjEW3xhNgV14G1fTV/39D5pcdudrKTyCd007DFE3/EFzBhQyfZd4HIvWPlAyJ3HD2hBqsKAJF7xxSB510wiMiNRuOUsnKIuGEfOMJVLlJgmLgybW+8CgIhO4kcxa4IZWr8qXTWWigk1Jg/EohkcZQAIsdzoaJrFRC5VZqETMcVACKnOxihPHUFmEXkpnNXFIUyQugiuIRq6Srwnrin7blrQTV039pP5EajUTTwBaAcW+J/pqD3sCi6Xcfp5YHIqS8eOJcEInccPaEGqwoAkeM88JluG+OI3Dil0cgL4TBEuujsivJtslqtvNDu8HGSphwichRQXi4dwZZKZ61hFcwJHyf7IhA505c0ZD8QuVWahEzHFQAi944pAs+7YB6RG40GjWqy4xhAuSsgm3qdbbLayY7jjuO4PeeRk/yEEropQ7VitIwhB4/MEkAvl6oZcdyhRV8CIsdzoaJrFRC54+gJNVhVAIic7mCE8tQVYCKRGwHKO1XU0dkVJb/h+DGDRmXBM/a9ddRHjk4or1aMzhLYxf82GYrj8IQg6isH5iWByK3SJGQ6rgAQOeZjn9HmMZTIAcpdwdkU6yQIgUZe6Cwcd4KP3NxTDuErHud15uI4EDmjFzNz44HIHUdPqMGqAkDk5gMN0s5VgLlEbsKwKY1WXthP3KOIklDMQQWqFL0DsnuTzogdN/emO8FHTkJ5bfeYEJ4c5KEAnjLpSJVilInBKmR3hKgV5y4wnqoNiNwqTUKm4woAkXtqUM+GdplN5N+gfLK/ZFx64blC4SBuwuUzK1AnF49LL0z2lzgldpxEIKf5yMka25UTcPqK+z3lAmKktnuMKU8CInuLRQKI3DuWPSByx9ETarCqABC5d0wReN4F44n824I6Pdyokea/k1XPzJTwqd0KmCJVpPnT6jcWAOOUt07zkZPWKMd18PAgd0J5uXSE+PiV1J+5CSByPBcqulYBkVulSch0XAEgcrqDEcpTV8A7iNwUVq4b1XYWqWVXG+StdnMnXPizAg3y1nHpBW1nkUHnqqOlnU/kRqNxQjdd0z0mgAgWF0ewCAl1tWL004SeuRRubjkQOfXFA+eSQOSOoyfUYFUBIHKcBz7TbfMaIker6rT6jVaaPyi7D0EsP7M13ZznCsUwcUUrzTeME+bQ4vS0S4gcWdk3OlkuVQsJOK3cJQoIZWrvcI2TfRqInOlLGrIfiNwqTUKm4woAkXvHFIHnXXgZkZsW1inN9IeayY5jQ8QN8JfTpXBUvlneiFh8eriRZBXXJVxI5OhgROLj13KpWgBPEXKSv7xMoi4nRpoHvkzopl3XLTxSMxA5ngsVXauAyB1HT6jBqgJA5HQHI5SnroAXEvmPhdzkL5cXTkjOEISgTi62j01n1VV1cnEXUTIhOaOVF7ooZPzHl/M//3ctkaOmdFMGxOXgL3ckvvwpoS6Xqlu8kcVRPwEip7544FwSiNwqTUKm4woAkeM88JlumxcTOVphDRqVfrBSS+RPSM4MyO69kdU1yNsA0NEvjTq5uEHe9kZWNyC7p5Uc1xL5+sEKJx40/j/cbfuNO4icbF05rqvvHS+VjDyVqR1h01l1rdAE4iPVitG+0Ummn6ZC9gSriW9ErhINwovZCuBN5If0YngxVQF8iRxmLeYr4PVETi67Bt3o9HDjZH+JtrNIIy9EP5XVsqvDxBWFTEgQgtnw6iGeDBNX1LKr6PY18kJtZ9Fkf8m0+o3rNm6SX4GthFuJHBmhmzIox3XN/Z8Rl1fITLHmAgg3/xbWYorwIUy/WMqlI+VSdX3veN/opPcFqFjtjv2fv8DLOxSYMhisfsWezZxWVcGL6QoY9J8924t+bt07xizcRf/nLz9/ubMlZ0pj+NJj+NIz/aFmana8pj/UoFvG6iv2AJFb3P+nCf2nCT3x8av0w9f63vGX3WMVs8yDXi5Vv+waq+0ek3z4Snz8igTxbne4RR+At6AAKAAKgAKgACgACsxmBTxP5LNZfbh3UAAUAAVAAVAAFAAFQAFQAIgc+gAoAAqAAqAAKAAKgAKgACjgSQWAyD2pPrQNCoACoAAoAAqAAqAAKAAKAJFDHwAFQAFQABQABUABUAAUAAU8qQAQuSfVh7ZBAVAAFAAFQAFQABQABUABIHLoA6AAKAAKgAKgACgACoACoIAnFQAi96T60DYoAAqAAqAAKAAKgAKgACgARA59ABQABUABUAAUAAVAAVAAFPCkAkDknlQf2gYFQAFQABQABUABUAAUAAWAyKEPgAKgACgACoACoAAoAAqAAp5UAIjck+pD26AAKAAKgAKgACgACoACoAAQOfQBUAAUAAVAAVAAFAAFQAFQwJMK/D8pwJpGO1AAdwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "7eb6e0cd",
   "metadata": {},
   "source": [
    "# DeOldify using OpenVINO\n",
    "\n",
    "DeOldify is an open-source deep learning project, that uses generative adversarial networks (GANs) to colorize and restore old black and white images and videos. The project is built using PyTorch and utilizes a deep neural network architecture to analyze and add color to grayscale images and videos.  More details about its realization can be found in original model [repository](https://github.com/jantic/DeOldify).\n",
    "\n",
    "This tutorial demonstrates how to convert and run the pytorch model for DeOldify with OpenVino.\n",
    "\n",
    "There are currently three models available: one to produce stable color results on images, one to produce artistic colors on an image and one to convert a video (More details on this is available on the original [repo link](https://github.com/jantic/DeOldify).\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edbf18b",
   "metadata": {},
   "source": [
    "## **Validate Pytorch model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05505543",
   "metadata": {},
   "source": [
    "## **Prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b38583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file as df  # noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320a9cb",
   "metadata": {},
   "source": [
    "## Clone the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e813b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone DeOldify repo\n",
    "if not Path('DeOldify').exists():\n",
    "    !git clone https://github.com/jantic/DeOldify.git\n",
    "%cd DeOldify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30f249",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c16d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9811b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc91416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # noqa: E402\n",
    "import re  # noqa: E402\n",
    "from typing import Union as Un  # noqa: E402\n",
    "from typing import Tuple  # noqa: E402\n",
    "import cv2  # noqa: E402\n",
    "import numpy as np  # noqa: E402\n",
    "import torch as tr  # noqa: E402\n",
    "import yt_dlp as youtube_dl  # noqa: E402\n",
    "from matplotlib import pyplot as plt  # noqa: E402\n",
    "from openvino.inference_engine import IECore  # noqa: E402\n",
    "from openvino.runtime import Core, serialize  # noqa: E402\n",
    "from openvino.tools import mo  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f138d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deoldify.generators as gen  # noqa: E402\n",
    "from deoldify.visualize import get_image_colorizer  # noqa: E402\n",
    "from deoldify.visualize import get_video_colorizer  # noqa: E402\n",
    "from deoldify.visualize import show_image_in_notebook  # noqa: E402\n",
    "from deoldify.visualize import show_video_in_notebook  # noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b867485",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfolder_check(color_source_path: str):\n",
    "    \"\"\"\n",
    "    Checks creates the specified directory if it doesn't exist.\n",
    "\n",
    "    Parameters:\n",
    "        color_source_path: Directory path to check and create.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not Path(color_source_path).exists():\n",
    "        os.mkdir(color_source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fffc4b",
   "metadata": {},
   "source": [
    "## Download pre-trained model weights and run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3387ed",
   "metadata": {},
   "source": [
    "We take user input in the cell below to decide if we want to generate results for an image or a video and also to check whether the model is expected to generate artistic output or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_type():\n",
    "    \"\"\"\n",
    "    Determines if input format is image or video\n",
    "    In case of image input, decides between artistic or stable results\n",
    "\n",
    "    Returns:\n",
    "        inputs: A list of two boolean values\n",
    "    \"\"\"\n",
    "    image = \"True\"  # make this false to load video inference\n",
    "    artistic = \"True\"  # make this false to generate stable results\n",
    "    inputs = [image, artistic]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000ddcb",
   "metadata": {},
   "source": [
    "Based on what we decide, either the pre-trained **ColorizeArtistic_gen.pth** is downloaded using the download_file function provided exclusively by OpenVino Toolkit or **ColorizeStable_gen.pth** is downloaded and for videos, we download the **ColorizeVideo_gen.pth**.\n",
    "\n",
    "ColorizeArtistic_gen.pth : The model uses a resnet34 backbone on a UNet with an emphasis on depth of layers on the decoder side. This model was trained with 5 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px. \n",
    "\n",
    "ColorizeStable_gen.pth : This model uses a resnet101 backbone on a UNet with an emphasis on width of layers on the decoder side. This model was trained with 3 critic pretrain/GAN cycle repeats via NoGAN, in addition to the initial generator/critic pretrain/GAN NoGAN training, at 192px.\n",
    "\n",
    "ColorizeVideo_gen.pth : The model is the same as \"stable\" in terms of architecture, but differs in training. It's trained at 192px, using only the initial generator/critic pretrain/GAN NoGAN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_type()[0]\n",
    "artistic = input_type()[1]\n",
    "\n",
    "if image == \"True\":\n",
    "    if artistic == \"True\":\n",
    "        if not Path('models/ColorizeArtistic_gen.pth').exists():\n",
    "            URL = \"https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth\"\n",
    "            MODEL_DIR = Path(\"models/\")\n",
    "            df(URL, directory=MODEL_DIR, show_progress=True)\n",
    "    else:\n",
    "        if not Path('models/ColorizeStable_gen.pth').exists():\n",
    "            !wget https://www.dropbox.com/s/axsd2g85uyixaho/ColorizeStable_gen.pth?dl=0 -O ./models/ColorizeStable_gen.pth\n",
    "else:\n",
    "    if not Path('models/ColorizeVideo_gen.pth').exists():\n",
    "        !wget https://data.deepai.org/deoldify/ColorizeVideo_gen.pth -O ./models/ColorizeVideo_gen.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c0fe7",
   "metadata": {},
   "source": [
    "Here is a black and white image of a beautiful women and using DeOldify, we will colorize it. But first lets download the image and store it under the test_images directory which is present in our cloned repository for DeOldify. This photo is taken from this [website](https://photo-works.net/how-to-make-picture-black-and-white.php) which converts a color photo to black and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_type()[0]\n",
    "if image == 'True':\n",
    "    img_url = \"https://tinyurl.com/3nrt3h4p\"\n",
    "    fname = \"image.png\"\n",
    "    folder = \"test_images\"\n",
    "    df(img_url, fname, folder, show_progress=True, silent=True, timeout=30)\n",
    "else:\n",
    "    subfolder_check('video')\n",
    "    subfolder_check('video/source')\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
    "        'outtmpl': str(Path(\"video/source/vid.mp4\")),\n",
    "        'retries': 30,\n",
    "        'fragment-retries': 30\n",
    "    }\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([\"https://tinyurl.com/2p884ea7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e677db",
   "metadata": {},
   "source": [
    "Down in the cells is the part where we load the model and get the colored image or video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc622f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = input_type()[0]\n",
    "\n",
    "\n",
    "def colorise(image):\n",
    "    if image == \"True\":\n",
    "        colorizer = get_image_colorizer(artistic=artistic)\n",
    "    else:\n",
    "        colorizer = get_video_colorizer()\n",
    "    return colorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_type()[0]\n",
    "cz = colorise(image)\n",
    "\n",
    "if image == \"True\":\n",
    "    # NOTE:  Max is 45 with 11GB video cards. 35 is a good default\n",
    "    rf = 35  # render_factor\n",
    "    # U='https://tinyurl.com/3nrt3h4p'\n",
    "    RP = None  # result path\n",
    "    F = (20, 20)  # figsize\n",
    "    U = None  # source_url\n",
    "    drf = False  # display_render_factor\n",
    "    P = 'test_images/image.png'  # source_path\n",
    "    C = True  # compare\n",
    "    pp = True  # post_process\n",
    "    W = True  # watermarked\n",
    "\n",
    "    if U is not None:\n",
    "        RP = cz.plot_transformed_image_from_url(U, P, RP, F, rf, drf, C, pp, W)\n",
    "    else:\n",
    "        RP = cz.plot_transformed_image(P, RP, F, rf, drf, C, pp, W)\n",
    "\n",
    "    show_image_in_notebook(RP)\n",
    "else:\n",
    "    # NOTE:  Max is 44 with 11GB video cards.  21 is a good default\n",
    "    r_f = 21  # render_factor\n",
    "#     s_u='https://twitter.com/silentmoviegifs/status/1116751583386034176'\n",
    "    s_u = None  # source_url\n",
    "    f_n = 'vid'  # file_name\n",
    "    f_n_e = f_n + '.mp4'  # file_name_extended\n",
    "    r_p = None  # result_path\n",
    "\n",
    "    if s_u is not None:\n",
    "        r_p = cz.colorize_from_url(s_u, f_n_e, r_f)\n",
    "    else:\n",
    "        r_p = cz.colorize_from_file_name(f_n_e, r_f)\n",
    "\n",
    "    show_video_in_notebook(r_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ab4f4",
   "metadata": {},
   "source": [
    "## Convert Pytorch model into onnx format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296fbe9b",
   "metadata": {},
   "source": [
    "Before we start converting the pytorch model into onnx format and later into OpenVino IR format, lets define some variables to improve code redability and minimize the number of if statements when switching models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = input_type()[0]\n",
    "artistic = input_type()[1]\n",
    "\n",
    "\n",
    "def attributes(image, artistic):\n",
    "    if image == \"True\":\n",
    "        if artistic == \"True\":\n",
    "            wt_name = \"ColorizeArtistic_gen\"\n",
    "            onnx_path = \"models/ColorizeArtistic_deoldify.onnx\"\n",
    "            onnx_name = \"ColorizeArtistic_deoldify.onnx\"\n",
    "            xml_name = \"models/ColorizeArtistic_deoldify.xml\"\n",
    "            bin_name = \"models/ColorizeArtistic_deoldify.bin\"\n",
    "        else:\n",
    "            wt_name = \"ColorizeStable_gen\"\n",
    "            onnx_path = \"models/ColorizeStable_deoldify.onnx\"\n",
    "            onnx_name = \"ColorizeStable_deoldify.onnx\"\n",
    "            xml_name = \"models/ColorizeStable_deoldify.xml\"\n",
    "            bin_name = \"models/ColorizeStable_deoldify.bin\"\n",
    "    else:\n",
    "        wt_name = \"ColorizeVideo_gen\"\n",
    "        onnx_path = \"models/ColorizeVideo_deoldify.onnx\"\n",
    "        onnx_name = \"ColorizeVideo_deoldify.onnx\"\n",
    "        xml_name = \"models/ColorizeVideo_deoldify.xml\"\n",
    "        bin_name = \"models/ColorizeVideo_deoldify.bin\"\n",
    "\n",
    "    return wt_name, onnx_path, onnx_name, xml_name, bin_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5401b6",
   "metadata": {},
   "source": [
    "Below we convert the pytorch model into onnx format.\n",
    "First we load the pytorch model. We need to remove the spectral normalizations after loading the model as this is an unsupported operator in ONNX and not doing so raises an error while exporting. We define a 192x192 image input size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a57320",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 192  # use 576 for better results or 96 if cell fails to run\n",
    "\n",
    "\n",
    "def refine_network(item: Un[tr.nn.Module, tr.nn.ModuleList, tr.nn.Sequential]):\n",
    "    \"\"\"\n",
    "    Recursively removes spectral normalization from all PyTorch modules.\n",
    "\n",
    "    It recursively traverses the input PyTorch module and its submodules.\n",
    "    Spectral normalization stabilizes the training of generative models.\n",
    "    After training, spectral normalization might be desirable to remove.\n",
    "    This function removes spectral normalization present in any module.\n",
    "\n",
    "    Parameters:\n",
    "        item : The PyTorch module to remove spectral normalization from.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if isinstance(item, tr.nn.Module):\n",
    "        try:\n",
    "            tr.nn.utils.remove_spectral_norm(item)\n",
    "        except Exception:\n",
    "            pass\n",
    "        for child in item.children():\n",
    "            refine_network(child)\n",
    "\n",
    "    if isinstance(item, tr.nn.ModuleList):\n",
    "        for module in item:\n",
    "            refine_network(module)\n",
    "\n",
    "    if isinstance(item, tr.nn.Sequential):\n",
    "        modules = item.children()\n",
    "        for module in modules:\n",
    "            refine_network(module)\n",
    "\n",
    "\n",
    "def export_to_onnx_and_test() -> None:\n",
    "    \"\"\"\n",
    "    Exports the DeOldify network as an ONNX model.\n",
    "\n",
    "    This function exports the model in ONNX format.\n",
    "    But 'mv' operation is not supported by torch.onnx.export.\n",
    "    This function also removes spectral normalization from the model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    image = input_type()[0]\n",
    "    artistic = input_type()[1]\n",
    "    W, onnx_path, onnx_n, xml, bin_name = attributes(image, artistic)\n",
    "    P = Path(\"./\")\n",
    "\n",
    "    print(\"> Load the DeOldify network\")\n",
    "    if image == \"True\":\n",
    "        if artistic == \"True\":\n",
    "            tr_m = gen.gen_inference_deep(root_folder=P, weights_name=W).model\n",
    "        else:\n",
    "            tr_m = gen.gen_inference_wide(root_folder=P, weights_name=W).model\n",
    "    else:\n",
    "        tr_m = gen.gen_inference_wide(root_folder=P, weights_name=W).model\n",
    "    tr_m.eval()\n",
    "\n",
    "    print(\"> Set example input to the model for exporting and for testing\")\n",
    "    example_input_t = tr.rand(1, 3, INPUT_SIZE, INPUT_SIZE)\n",
    "\n",
    "    print(\"> Export the model as ONNX format\")\n",
    "    refine_network(tr_m)  # 'mv' operation not supported by torch.onnx.export\n",
    "    tr.onnx.export(\n",
    "        tr_m,\n",
    "        example_input_t,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=9,\n",
    "        do_constant_folding=False,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"])\n",
    "\n",
    "\n",
    "export_to_onnx_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa7163",
   "metadata": {},
   "source": [
    "## Convert onnx model into openvino Ir format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312002d",
   "metadata": {},
   "source": [
    "Although the OpenVINO runtime directly supports ONNX models, it may be advantageous to convert them to IR format in order to make use of the OpenVINO optimisation tools and capabilities. To convert a model using OpenVINO Model Optimizer, use the mo.convert model Python function. Instances of the OpenVINO Model class are returned by the function, ready for usage in the Python interface but also capable of being serialised to the OpenVINO IR format for later execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_name, onnx_path, onnx_name, xml_name, bin_name = attributes(image, artistic)\n",
    "model = mo.convert_model(onnx_path)\n",
    "# serialize model for saving IR\n",
    "serialize(model, xml_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a9cda5",
   "metadata": {},
   "source": [
    "## Run inference from Openvino IR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debc719",
   "metadata": {},
   "source": [
    "Next we set up the environment for deploying an OpenVINO optimized model on a CPU device and obtain information about the model input and output layers. Our process typically begins with preprocessing, then uses OpenVINO model inference and results post-processing to provide a colourized output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e40a66",
   "metadata": {},
   "source": [
    "## Image Processing - PreProcessing + PostProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c23c4",
   "metadata": {},
   "source": [
    "Model input is in accordance with shape [1, 3, 192, 192] in N, C, H, W format, where\n",
    "\n",
    "N - number of images in batch (batch size)\n",
    "\n",
    "C - image channels\n",
    "\n",
    "H - image height\n",
    "\n",
    "W - image width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c531fbd",
   "metadata": {},
   "source": [
    "The pre_processing function takes an image in the form of a NumPy array as input, resizes it to a specific size using cv2.resize, converts it to a float tensor with pixel values in the range [0, 1], and normalizes pixel values using mean [0.485, 0.456, 0.406] and standard deviation [0.229, 0.224, 0.225]. The final output of the function is a float tensor after preprocessing.\n",
    "\n",
    "The post_processing function takes the output of a computer vision model in the form of a NumPy array as input, and post-processes it to obtain a coloured image of the same size as that of the input image. The function first normalizes the pixel values using cv2.normalize, scales the pixel values by 255, transposes the dimensions of the array, reverses the order of the channels, and converts the pixel values to unsigned 8-bit integers. The function then resizes the image to the original size of the input image and converts it to RGB format. Finally, the function returns the postprocessed image as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50412184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(img: np.ndarray, W: int, H: int):\n",
    "    \"\"\"\n",
    "    Preprocess image according to DeOldify input requirements.\n",
    "    Converts preprocessed image to tensor format.\n",
    "    Changes data layout from HWC to CHW.\n",
    "\n",
    "    Converts image in np.array format with unit8 data in [0, 255] range\n",
    "    to torch.Tensor object with float data in [0, 1] range.\n",
    "    Normalizes pixel values using mean [0.485, 0.456, 0.406]\n",
    "    and standard deviation [0.229, 0.224, 0.225].\n",
    "\n",
    "    Parameters:\n",
    "      img (np.ndarray): image for preprocessing\n",
    "      W : Image width that the OpenVino IR model expects\n",
    "      H : Image height that the OpenVino IR model expects\n",
    "\n",
    "    Returns:\n",
    "      final_input (torch.Tensor): float tensor after preprocessing\n",
    "\n",
    "    Note:\n",
    "    This function assumes that the input image is in BGR format.\n",
    "    \"\"\"\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    np_data = cv2.resize(img, (W, H)).astype(np.float32) / 255\n",
    "    np_data -= np.array([0.485, 0.456, 0.406])\n",
    "    np_data /= np.array([0.229, 0.224, 0.225])\n",
    "    inter_value = np_data.transpose((2, 0, 1))\n",
    "    final_input = np.expand_dims(inter_value, 0).astype(np.float32)\n",
    "    return final_input\n",
    "\n",
    "\n",
    "def post_processing(colour_data: np.ndarray, imshow_size: Tuple[int, int]):\n",
    "    \"\"\"\n",
    "    Postprocesses the output of a model to obtain a coloured image\n",
    "    of the same size as that of input image.\n",
    "    Major postprocessing steps involves normalization , scaling and resizing.\n",
    "\n",
    "    Parameters:\n",
    "        colour_data (np.ndarray): The output of the computer vision model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The postprocessed image as a NumPy array.\n",
    "    \"\"\"\n",
    "    data = np.squeeze(colour_data)\n",
    "    post_data = cv2.normalize(\n",
    "        data,\n",
    "        None,\n",
    "        alpha=0,\n",
    "        beta=1,\n",
    "        norm_type=cv2.NORM_MINMAX\n",
    "    )\n",
    "    inter_colour_data = post_data.transpose(1, 2, 0)[:, :, ::-1] * 255\n",
    "    updated_colour_data = inter_colour_data.astype(np.uint8)\n",
    "    final_colour_data = cv2.resize(updated_colour_data, imshow_size)\n",
    "    final_img = cv2.cvtColor(final_colour_data, cv2.COLOR_BGR2RGB)\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d40aa",
   "metadata": {},
   "source": [
    "The cell given below are for loading inference on an image. Do not use this to colourise a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = Core()\n",
    "# read converted model\n",
    "image = input_type()[0]\n",
    "artistic = input_type()[1]\n",
    "wt_name, onnx_path, onnx_name, xml_name, bin_name = attributes(image, artistic)\n",
    "model = core.read_model(xml_name)\n",
    "# load model on CPU device\n",
    "compiled_model = core.compile_model(model, 'CPU')\n",
    "input_layer = compiled_model.input(0)\n",
    "N, C, H, W = input_layer.shape\n",
    "output_layer = compiled_model.output(0)\n",
    "print('Model Input and Output Info')\n",
    "print(f\"- input shape: {input_layer.shape}\")\n",
    "print(f\"- input precision: {input_layer.element_type}\")\n",
    "print(f\"- output shape: {output_layer.shape}\")\n",
    "print(f\"- output precision: {output_layer.element_type}\")\n",
    "image = input_type()[0]\n",
    "image_filename = 'test_images/image.png'\n",
    "img = cv2.imread(image_filename)\n",
    "(h_orig, w_orig) = img.shape[:2]\n",
    "imshow_size = (w_orig, h_orig)\n",
    "input_img = pre_processing(img, W, H)\n",
    "result = compiled_model([input_img])[output_layer]\n",
    "coloured_img = post_processing(result[0], imshow_size)\n",
    "plt.imshow(coloured_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d514b2",
   "metadata": {},
   "source": [
    "## Video Processing - PreProcessing + PostProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39463914",
   "metadata": {},
   "source": [
    "In the module below, we colorise a video by breaking it down into frames and then feeding those frames as input to the DeOldify IR model. To do so, we first create a directory called bwframes which is done in the function call. Still we check if a directory called bwframes is correctly created or not. Next, we create a directory called colorframes inside the video directory to store the colorised frames. We then build the video back from the colorised frames and save it in the results directory inside the video folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = input_type()[0]\n",
    "artistic = input_type()[1]\n",
    "wt_name, onnx_path, onnx_name, xml_name, bin_name = attributes(video, artistic)\n",
    "\n",
    "ie = IECore()\n",
    "\n",
    "model_xml = xml_name\n",
    "model_bin = bin_name\n",
    "\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "input_blob = next(iter(net.input_info))\n",
    "output_blob = next(iter(net.outputs))\n",
    "\n",
    "exec_net = ie.load_network(network=net, device_name='CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video_frame(input_image: np.ndarray, W: int, H: int):\n",
    "    \"\"\"\n",
    "    Preprocessing a video frame in accordance with DeOldify input specification\n",
    "    Converts it to tensor format and switches the data layout from HWC to CHW.\n",
    "    Uses cv2.resize to resize an image in np.array format to a particular size.\n",
    "    Unit8 data between [0, 255] to tensor object with float data between [0, 1]\n",
    "    Normalize image using mean [0.485, 0.456, 0.406] and standard deviation\n",
    "    [0.229, 0.224, 0.225].\n",
    "\n",
    "    Parameters:\n",
    "        input_image (np.ndarray): An array representing a video frame.\n",
    "        W (int): Image width that the OpenVino IR model expects\n",
    "        H (int): Image height that the OpenVino IR model expects\n",
    "\n",
    "    Returns:\n",
    "        video_frame : A preprocessed video frame of shape (1, 3, W, H)\n",
    "                      ready to be fed into a deep learning model.\n",
    "\n",
    "    \"\"\"\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_GRAY2BGR)\n",
    "    input_image = cv2.resize(input_image, (W, H)).astype(np.float32) / 255\n",
    "    input_image -= np.array([0.485, 0.456, 0.406])\n",
    "    input_image /= np.array([0.229, 0.224, 0.225])\n",
    "    input_image = np.expand_dims(input_image.transpose((2, 0, 1)), 0)\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    video_frame = input_image.reshape((1, 3, W, H))\n",
    "    return video_frame\n",
    "\n",
    "\n",
    "def postprocess_video_frame(output: np.ndarray, shape, output_blob):\n",
    "    \"\"\"\n",
    "    Postprocesses the output of a model for a video frame to colourise the it.\n",
    "\n",
    "    Paameters:\n",
    "        output: An array representing the output of a deep learning model.\n",
    "        shape: A tuple representing the shape of the original frame.\n",
    "        output_blob: Output layer name of the deep learning model as string.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A postprocessed video frame of the original shape.\n",
    "\n",
    "    \"\"\"\n",
    "    data = np.squeeze(output[output_blob][0])\n",
    "    norm = cv2.NORM_MINMAX\n",
    "    op_data = cv2.normalize(data, None, alpha=0, beta=1, norm_type=norm)\n",
    "    output_image = op_data.transpose(1, 2, 0)[:, :, ::-1] * 255\n",
    "    output_image = output_image.astype(np.uint8)\n",
    "    output_image = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
    "    output_image = cv2.resize(output_image, shape)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4709b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def folder_check(folder_pth: str, folder_name: str):\n",
    "    \"\"\"\n",
    "    Checks if a specific directory exists in the 'video' folder.\n",
    "    If the directory doesn't exist, creates it.\n",
    "    Else, deletes all the '.jpg' files in the directory.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not Path(folder_pth).exists():\n",
    "        %cd video\n",
    "        os.mkdir(folder_name)\n",
    "    else:\n",
    "        %cd video\n",
    "    for f in os.listdir(folder_name):\n",
    "        if re.search('.*?\\.jpg', f):  # noqa\n",
    "            os.remove(os.path.join(folder_name, f))\n",
    "    %cd ..\n",
    "\n",
    "\n",
    "image = input_type()[0]\n",
    "if image != \"True\":\n",
    "    colorizer = colorise(image)\n",
    "    file_name = \"vid\"\n",
    "    file_name_ext = file_name + \".mp4\"\n",
    "    workfolder = Path(\"./video\")\n",
    "    source_folder = workfolder / \"source\"\n",
    "    source_path = source_folder / file_name_ext\n",
    "    colorizer._extract_raw_frames(Path(source_path))\n",
    "\n",
    "    subfolder_check(\"video/bwframes/\")\n",
    "    bwframes_folder = \"video/bwframes/\" + file_name\n",
    "    color_source_path = \"video/colorframes/\" + file_name\n",
    "    folder_check(\"video/colorframes/\", \"colorframes\")\n",
    "    subfolder_check(color_source_path)\n",
    "\n",
    "    for img in progress_bar(os.listdir(bwframes_folder)):  # noqa: F821\n",
    "        img_path = bwframes_folder + \"/\" + img\n",
    "\n",
    "        if os.path.isfile(str(img_path)):\n",
    "            read_frame = cv2.imread(img_path)\n",
    "            shape = (read_frame.shape[1], read_frame.shape[0])\n",
    "            input_frame = preprocess_video_frame(read_frame)\n",
    "            output = exec_net.infer(inputs={input_blob: input_frame})\n",
    "            color_image = postprocess_video_frame(output, shape, output_blob)\n",
    "            cv2.imwrite(str(color_source_path + \"/\" + img), color_image)\n",
    "    result_path = colorizer._build_video(Path(source_path))\n",
    "    show_video_in_notebook(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7411245",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
